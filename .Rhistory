getwd()
exit
version
exit
for(i in 1:length(naRepacedData[,1])) {
library(lattice)
sum.step <- with(totalSteps, tapply(totalSteps$steps, totalSteps$date, sum))
library(lattice
names(activityDataWithNAReplaced)[1] <- "day"
median(activityDataWithNAReplaced$steps, na.rm = TRUE)
## Loading Data
x <- 1:4
p <- x/sum(x)
temp <- rbind(x, p)
rownames(temp) <- c("X", "Prob")
temp
x <- 1:4
p <- x/sum(x)
temp <- rbind(x, p)
rownames(temp) <- c("X", "Prob")
temp
mean(temp)
mean(temp[x])
mean(temp[p])
mean(temp)
x <- 1:4
p <- x/sum(x)
temp <- rbind(x, p)
rownames(temp) <- c("X", "Prob")
temp
mean(temp)
1.0 * .1
1.0 * .1
2.0 * .2
3.0 * .3
4.0 * .4
clear
clr
1.0 * .1
2.0 * .2
3.0 * .3
4.0 * .4
y <- (.1,.4,.9,1.6)
y <- (0.1,0.4,0.9,1.6)
mean(0.1,0.4,0.9,1.6)
x <- 1:4
p <- x/sum(x)
temp <- rbind(x, p)
rownames(temp) <- c("X", "Prob")
temp
mean <- sum(temp[1, ]*temp[2, ])
mean
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
z <- x*w
mean(z)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
fit.origin <- lm( y ~ x - 1 )
summary(fit.origin)
data(mtcars)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
fit.origin <- lm( y ~ x - 1 )
summary(fit.origin)
data(mtcars)
fit <- lm(mpg ~ wt, mtcars)
summary(fit)
data(mtcars)
fit <- lm(mpg ~ wt, mtcars)
summary(fit)
data(mtcars)
fit <- lm(mpg ~ wt, mtcars)
summary(fit)
data(mtcars)
fit <- lm(mpg ~ wt, mtcars)
summary(fit)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
fit.origin <- lm( y ~ x - 1 )
summary(fit.origin)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
z <- x*w
mean(z)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
m.x <- mean(x)
sd.x <- sd(x)
(x[1] - m.x)/sd.x
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm( y ~ x )
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
optimize( function(u){ sum(w*(x-u)^2) }, interval=c(-100,100))
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y~x)
summary(fit)
e <- resid(fit)
sqe <- e*e
res.var <- sum(sqe) / (length(e) - 2)
sqrt(res.var)
data(mtcars)
attach(mtcars)
fit <- lm(mpg ~ wt, mtcars)
summary(fit)
exp <- fit$coefficients[1] + mean(wt) * fit$coefficients[2]
exp - 2 * 0.5591
?mtcars
summary(fit)
fit[[1]][1] + 3 * fit[[1]][2]
summary(fit)
2 * (fit$coefficients[2] - 2 * 0.5591)
attributes(fit)
w.c <- fit$residuals ^ 2
fit.c <- lm(mpg ~ 1, mtcars)
fit.c.res <- fit.c$residuals ^ 2
sum(fit.c.res)
sum(w.c) /sum(fit.c.res)
fit[[1]][1] + 3 * fit[[1]][2]
data(mtcars)
attach(mtcars)
fit <- lm(mpg ~ wt, mtcars)
fit[[1]][1] + 3 * fit[[1]][2]
summary(fit)
fit[[1]][1] + 3 * fit[[1]][2]
summary(fit)
fit[[1]][1] + 3 /fit[[1]][2]
data(mtcars)
fit <- lm(mpg ~ factor(cyl) + wt, mtcars)
summary(fit)
fit2 <- lm(mpg ~ factor(cyl), mtcars)
summary(fit2)
plot(fit2)
summary(fit3)
data(mtcars)
fit3 <- lm(mpg ~ factor(cyl)*wt, mtcars)
summary(fit3)
fit3
summary(fit3)
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
lm.influence(fit)$hat
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y~x)
lm.influence(fit)$hat
dfbetas(fit)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
# Give the hat diagonal for the most influential point
fit <- lm(y ~ x)
hatvalues(fit)
data(mtcars)
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2 <- lm(mpg ~ factor(cyl) + wt + interaction(cyl, wt), data = mtcars)
# To compare model we usually use an anova table
# anova null hypothesis says that both models are the same.
compare <- anova(fit1, fit2)
compare$Pr
data(mtcars)
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2 <- lm(mpg ~ factor(cyl) + wt + interaction(cyl, wt), data = mtcars)
# To compare model we usually use an anova table
# anova null hypothesis says that both models are the same.
compare <- anova(fit1, fit2)
compare$Pr
l1<-lm(mpg ~ factor(cyl)+wt, data = mtcars)
l2<-lm(mpg ~ factor(cyl)*wt, data = mtcars)
library(lmtest)
lrtest(l2,l1)
library(lmtest)
install.packages("lmtest")
l1<-lm(mpg ~ factor(cyl)+wt, data = mtcars)
l2<-lm(mpg ~ factor(cyl)*wt, data = mtcars)
library(lmtest)
lrtest(l2,l1)
data(mtcars)
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2 <- lm(mpg ~ factor(cyl) + wt + interaction(cyl, wt), data = mtcars)
# To compare model we usually use an anova table
# anova null hypothesis says that both models are the same.
compare <- anova(fit1, fit2)
compare$Pr
Ho is rejected, because TS(t = `r th$statistic`) > qt(1-alpha,`r th$parameter`)( = `r qt(1-alpha,th$parameter)`).
install.packages("swirl")
library(swirl)
swirl()
plot(child ~ parent, galton)
exit
q
plot(jitter(child,4) ~ parent,galton)"
exit
q
q
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_str <- grep("^IL", colnames(training), value = TRUE)
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.9)
preProc$rotation
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
b <- varImp(a)
order(b)
set.seed(33833)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
install.packages("randomForest")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
library(caret)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
library(randomForest)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
b <- varImp(a)
order(b)
# install.packages("RCurl")
library(RCurl)
library(caret)
trainingDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainingData <- read.csv(textConnection(getURL(trainingDataURL)), na.strings = c("NA", ""))
testData <- read.csv(textConnection(getURL(trainingDataURL)), na.strings = c("NA", ""))
plot(x = trainSet[, names], y = trainSet$classe)
names
# install.packages("RCurl")
library(RCurl)
library(caret)
trainingDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainingData <- read.csv(textConnection(getURL(trainingDataURL)), na.strings = c("NA", ""))
testData <- read.csv(textConnection(getURL(testDataURL)), na.strings = c("NA", ""))
#clean up data
NAs <- apply(trainingData, 2, function(x) {
sum(is.na(x))
})
cleanTrainingData <- trainingData[, which(NAs == 0)]
cleanTestData <- testData[, which(NAs == 0)]
dim(cleanTrainingData)
dim(cleanTestData)
##Using 70% for training and 30% for Cross Validation. None generated for testing since that set is already provided.
trainIndex <- createDataPartition(y = cleanTrainingData$classe, p = 0.7, list = FALSE)
trainSet <- cleanTrainingData[trainIndex, ]
crossValidationSet <- cleanTrainingData[-trainIndex, ]
# Removing variables that have time, or names in it, also new_window.
# Columns 1..6
removeIndex <- as.integer(c(1, 2, 3, 4, 5, 6))
trainSet <- trainSet[, -removeIndex]
testSet <- cleanTestData[, -removeIndex]
crossValidationSet <- crossValidationSet[, -removeIndex]
dim(trainSet)
dim(testSet)
dim(crossValidationSet)
names <- colnames(trainSet)
names <- names[-length(names)]
names
qplot(trainSet[, names],trainSet$classe,colour=trainSet$classe,data=trainSet)
qplot(,trainSet$classe,colour=trainSet$classe,data=trainSet)
plot(x = trainSet[, names], y = trainSet$classe)
head(trainSet)
qplot(,trainSet$classe,colour=trainSet[, names],data=trainSet)
# install.packages("RCurl")
library(RCurl)
library(caret)
trainingDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainingData <- read.csv(textConnection(getURL(trainingDataURL)), na.strings = c("NA", ""))
testData <- read.csv(textConnection(getURL(testDataURL)), na.strings = c("NA", ""))
#clean up data
NAs <- apply(trainingData, 2, function(x) {
sum(is.na(x))
})
cleanTrainingData <- trainingData[, which(NAs == 0)]
cleanTestData <- testData[, which(NAs == 0)]
dim(cleanTrainingData)
dim(cleanTestData)
##Using 70% for training and 30% for Cross Validation. None generated for testing since that set is already provided.
trainIndex <- createDataPartition(y = cleanTrainingData$classe, p = 0.7, list = FALSE)
trainSet <- cleanTrainingData[trainIndex, ]
crossValidationSet <- cleanTrainingData[-trainIndex, ]
# Removing variables that have time, or names in it, also new_window.
# Columns 1..6
removeIndex <- as.integer(c(1, 2, 3, 4, 5, 6))
trainSet <- trainSet[, -removeIndex]
testSet <- cleanTestData[, -removeIndex]
crossValidationSet <- crossValidationSet[, -removeIndex]
dim(trainSet)
dim(testSet)
dim(crossValidationSet)
####
library(randomForest)
library(caret)
set.seed(13333)
fitControl<-trainControl(method="cv", number=5, allowParallel=T, verbose=T)
modelFit <- train(trainSet$classe ~ ., data = trainSet, method = "rf", trControl = fitControl)
plot(modelFit)
inVarImp <- createDataPartition(y = trainSet$classe, p = 0.1, list = F)
varImpSub <- trainSet[inVarImp, ]
varImpRF <- train(classe ~ ., data = varImpSub, method = "rf")
varImpObj <- varImp(varImpRF)
plot(varImpObj, main = "Variable Importance of Top 52", top = 52)
# install.packages("RCurl")
library(RCurl)
library(caret)
trainingDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainingData <- read.csv(textConnection(getURL(trainingDataURL)), na.strings = c("NA", ""))
testData <- read.csv(textConnection(getURL(testDataURL)), na.strings = c("NA", ""))
#clean up data
NAs <- apply(trainingData, 2, function(x) {
sum(is.na(x))
})
cleanTrainingData <- trainingData[, which(NAs == 0)]
cleanTestData <- testData[, which(NAs == 0)]
dim(cleanTrainingData)
sum(complete.cases(cleanTrainingData))
head(cleanTrainingData)
summary(cleanTrainingData)
dim(cleanTrainingData)
sum(complete.cases(cleanTrainingData))
head(cleanTrainingData)
summary(cleanTrainingData)
Near_Zero_val <- nearZeroVar(cleanTrainingData)
Near_Zero_val <- nearZeroVar(cleanTrainingData)
Near_Zero_val <- nearZeroVar(cleanTrainingData)
summary(cleanTrainingData)
Near_Zero_val <- nearZeroVar(cleanTrainingData)
Near_Zero_val
setwd("~/git/PracticalMachineLearning")
# install.packages("RCurl")
library(RCurl)
library(caret)
trainingDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainingData <- read.csv(textConnection(getURL(trainingDataURL)), na.strings = c("NA", ""))
testData <- read.csv(textConnection(getURL(testDataURL)), na.strings = c("NA", ""))
#clean up data
NAs <- apply(trainingData, 2, function(x) {
sum(is.na(x))
})
cleanTrainingData <- trainingData[, which(NAs == 0)]
cleanTestData <- testData[, which(NAs == 0)]
qplot(cleanTrainingData$classe, data = cleanTrainingData, geom = "bar")
setwd("~/git/Prediction_Assignment_Writeup")
sum(complete.cases(trainingData))
The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har.
head?
setwd("~/git/Prediction_Assignment_Writeup")
clear
setwd("~/git/Prediction_Assignment_Writeup")
